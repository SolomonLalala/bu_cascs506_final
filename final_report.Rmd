---
title: "Building an epigenetic clock based on methods and data from Hannum et al"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
library(tidyverse)
source("scripts/helper.R")
```

# Collect data
```{r parse data from geo}
# set parameters
data_dir <- "data"
gse_accession <- "GSE40279"

# get data from geo
data_list <- parse_geo(dest_dir = data_dir, gse_id = gse_accession, transpose = TRUE, save = TRUE)
```

# Process data
## Extract metadata and merge with methylation data
```{r merge data}
# extract relevant metadata
metadata <- data_list[[2]] %>%
  select(
    sample_id = geo_accession,
    age = contains("age"),
    ethnicity = contains("ethnicity"),
    sex = contains("gender")
  ) %>%
  mutate(age = as.numeric(age))

# add sample id to methylation df
expr40279_df <- data_list[[1]]
expr40279_df$sample_id <- rownames(expr40279_df)

# merge methylation data with metadata
merged40279 <- inner_join(expr40279_df, metadata, by = "sample_id")

```

## Split data into train and test sets
```{r split data}
train_test_list <- split_train_test(
  dataset = merged40279, 
  train_frac = 0.75, 
  stratifier = "age", 
  dest_dir = data_dir, 
  save = TRUE)
train_set <- train_test_list[[1]]
test_set <- train_test_list[[2]]
```

## check subset data distribution
```{r}
# Check age distribution
summary(train_set$age)
summary(test_set$age)

# Check gender balance
table(train_set$sex)
table(test_set$sex)
```

## split data into predictor and target
```{r split data}
X_train <- train_set %>%
  select(-sample_id, -age, -ethnicity, -sex) # predictor
y_train <- train_set$age # prediction target

X_test <- test_set %>%
  select(-sample_id, -age, -ethnicity, -sex)
y_test <- test_set$age

saveRDS(X_train, file = file.path(data_dir, "X_train.rds"))
saveRDS(y_train, file = file.path(data_dir, "y_train.rds"))
saveRDS(X_test, file = file.path(data_dir, "X_test.rds"))
saveRDS(y_test, file = file.path(data_dir, "y_test.rds"))
```

## standardize data
```{r center and scale data}
# obtain mean and sd
preProcValues <- preProcess(as.matrix(X_train), method = c("center", "scale"))

# Apply the transformation to the data
X_train_standardized <- predict(preProcValues, as.matrix(X_train))
X_test_standardized <- predict(preProcValues, as.matrix(X_test))

# save prepro_values
saveRDS(preProcValues, file = file.path(data_dir, "preProcValues.rds"))
# save the standardized data
saveRDS(X_train_standardized, file = file.path(data_dir, "X_train_standardized.rds"))
saveRDS(X_test_standardized, file = file.path(data_dir, "X_test_standardized.rds"))
```


# Train model
## Set parameters
```{r set parameters}
alpha = 0.5
n_cores <- parallel::detectCores() - 1
n_fold = 10
iterations = 500
model_params <- list(
  n_cores = n_cores,
  alpha = alpha,
  n_fold = n_fold,
  iterations = iterations
)

saveRDS(model_params, file = file.path(data_dir, "model_params.rds"))
```

## Optimize parameters
###Cross-validation
```{bash}
qsub scripts/cv.sh
# Or run locally
# Rscript -e "source('scripts/cv.R')"
```

### Find lambda
```{r}
cv_model <- readRDS(file.path(data_dir, "cv_model.rds"))
plot(cv_model)
lambda_min <- cv_model$lambda.min
saveRDS(lambda_min, file = file.path(data_dir, "lambda_min.rds"))
```

## Select feature
### Bootstrap
```{bash}
qsub scripts/bootstrap.sh
```

### Select CpGs(feature) 
```{r}
bootstrap_res <- readRDS(file.path(data_dir, "bootstrap_results.rds"))
cpgs_selected <- select_feature(
  bootstrap_results = bootstrap_res, 
  threshold = 0.5,
  dest_dir = data_dir)
```

## Train final model
```{r}
set.seed(123)
final_model <- glmnet(
    X_train_standardized, 
    y_train, 
    alpha = alpha, 
    lambda = lambda_min, 
    type.measure = "mse",
    family = "gaussian",
    standardize = FALSE)
```

# Evaluate model
```{r}
y_pred <- predict(final_model, newx = as.matrix(X_test), s = lambda_min)
y_pred <- as.numeric(y_pred)
results_df <- data.frame(
  Sample = test_set$sample_id,
  Actual_Age = y_test,
  Predicted_Age = y_pred
)
```














